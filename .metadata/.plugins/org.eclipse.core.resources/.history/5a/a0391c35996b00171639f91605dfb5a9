from scrapy.spider import BaseSpider
from scrapy.selector import HtmlXPathSelector
from tutorial.items import DmozItem

class DmozSpider(BaseSpider):
    name = "dmoz"#spider的名字
    allowed_domains = ["dmoz.org"]
    start_urls = [
        "http://localhost:8008/index.html",
        "http://localhost:8008/index.aspx"
    ]    #待抓取的列表
  
    def parse(self, response):
        self.log("Fetch localhost homepage page: %s" % response.url)
        hxs = HtmlXPathSelector(response)
        sites = hxs.select('//div[contains(@class, "article-item clearfix")]')
        #sites = hxs.path('//ul/li')
        items=[]
        for site in sites:
            item = DmozItem()
            item['title'] = site.select('div[contains(@class, "article-item-title")]/a/text()').extract()[0]
            if len(site.select('div[contains(@class, "article-item-title")]/a/span/text()').extract())>0:
                item['title']+=site.select('div[contains(@class, "article-item-title")]/a/span/text()').extract()[0]
            
            item['link'] = site.select('div[contains(@class, "article-item-title")]/a/@href').extract()[0]
            #item['desc'] = site.select('div[contains(@class, "content-warp")]/p/text()').extract()+site.select('div[contains(@class, "content-warp")]/p/span/text()').extract()
            item['desc'] = "++".join(site.select('div[contains(@class, "content-warp")]/p/text()').extract_unquoted())
            
            #print title, link, desc
            items.append(item)
            print (item['title'], item['link'], item['link'])
        return items
